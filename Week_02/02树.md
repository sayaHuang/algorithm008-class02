[TOC]

#  树
## 什么是树
森林里面的树, 和数据结构里面的树, 样子很像, 有主干和枝杈. 

```swift
    3        root 根节点
   / \
  9  20      20 相对于 15/7为父节点, 相对于3 为子节点, 相对于 9 为兄弟节点
    /  \
   15   7    9 相对于 7(或15) 为叔叔节点
             9 / 15 / 7 均为叶子节点
```
`高度`, 从叶子结点按0开始计算, 往上数依次+1  
`深度`, 从根结点按0开始计算, 往下数依次+1   
`层` , 从根结点按1开始计算, 往下数依次+1   

### 特殊的树
`二叉树`的每个节点最多有两个子节点，分别是左子节点和右子节点  
`完全二叉树`: 叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大
`满二叉树` (特殊的完全二叉树) :  叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点  

## 树的存储
**数组:** 数组适合存储, 完全二叉树  
```swift
     17        
   /    \
  9     20     
 / \   /  \
6  10 15   27    
```
array[1] = 17,  
array[2] = 9, array[3] = 20,  
array[4] = 6, array[5] = 10,array[6] = 15, array[7] = 27  
```
假设  index = 2
     左子节点 = index * 2
     右子节点 = index * 2 + 1
     父结点 = index / 2
```
从上面的例子不难看出 为什么数组适合保存 完全二叉树了吧, 也可以理解为什么 完全二叉树的最底层叶子结点需要靠左了吧, 这样存储的时候可以少浪费一些数组空间  

**链表:** 合适存储树, 但是无法完全发挥CPU的缓存效率, 多次插入,删除,造成内存空间碎片化, 所以完全二叉树推荐数组存储  

## 遍历函数
前中后, 标识着 root 什么时候输出
```C++
void preOrder(Node* root) {
  if (root == null) return;
  println(root); 
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  println(root); 
  print root // 此处为伪代码，表示打印root节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  println(root); 
}
```
时间复杂度: O(N)
空间复杂度: O(N)

### 遍历函数图解
![treeOrder.png](../images/treeOrder.png)

## 二叉查找树(有名: 二叉搜索树)
**二叉查找树, 要求在树种任意一个结点, 左子树结点的值都小于该结点值, 右子树结点的值都大于该结点值**  

### 查找
上代码
```java
public class BinarySearchTree {
		private Node root;
		public Node find(int data) {
				Node p = root;
				//实用迭代的方法
				while (p != null) {
						//data和目标节点对比, 小于目标结点,则继续在左子树查询
						if (data < p.data) p = p.left;
						//data和目标节点对比, 大于目标结点,则继续在右子树查询
						else if (data > p.data) p = p.right;
						else return p;
				}
				return null;
		}
}
```

### 插入
插入类似查找
```java
public void insert(int data) {
		if (root == null) { 
				root = new Node(data);
				return;
		}
		
		Node p = tree;
		while (p != null) {
				//data和目标节点对比, 小于目标结点, 如果目标的左边为空, 则直接插入
				if (data < p.data) {
						if (p.left == null) {
								p.left = new Node(data);
								return;
						}
						//否则, 继续在左子树寻找合适的位置
						p = p.left
				} else {
						//同理
						if (p.right == null) {
								p.right = new Node(data);
								return;
						}
						p = p.right
				} 
		}
}
```

### 插入的时候遇到值相等的数据了
解决办法一: 在遇到相同的时候, 使用支持动态扩容的数据结构, 将相同的数据保存为一个链表, 树的节点保存一个链表

解决办法二: 遍历的时候发现 等于正在对比的节点, 将这个要插入的数据当作大于节点的值来处理, 继续在对比节点的右子树中寻找适合位置。  
删除的时候, 遇到相等的值, 不能停止, 继续在右子树中查询, 直到叶子节点, 删除所有  

### 删除
```java
public void delete(int data) {
  Node p = root; // p指向要删除的节点，初始化指向根节点
  //先找到这个节点
  Node pp = null; // pp记录的是p的父节点
  while (p != null && p.data != data) {
    pp = p;
    if (data > p.data) p = p.right;
    else p = p.left;
  }
  if (p == null) return; // 没有找到

  // 要删除的节点有两个子节点
  if (p.left != null && p.right != null) { // 查找右子树中最小节点
    Node minP = p.right;
    Node minPP = p; // minPP表示minP的父节点
    while (minP.left != null) {
      minPP = minP;
      minP = minP.left;
    }
    p.data = minP.data; // 将minP的数据替换到p中
    p = minP; // 下面就变成了删除minP了
    pp = minPP;
  }

  // 删除节点是叶子节点或者仅有一个子节点
  Node child; // p的子节点
  if (p.left != null) child = p.left;
  else if (p.right != null) child = p.right;
  else child = null;

  if (pp == null) root = child; // 删除的是根节点
  else if (pp.left == p) pp.left = child;
  else pp.right = child;
}
```
> 二叉查找树的删除操作，还有个非常简单、取巧的方法，就是单纯将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉。这样原本删除的节点还需要存储在内存中，比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。

### 二叉树其他操作
1. 快速查找最大值 , 最小值
2. 中序遍历, 可以输出有序的数组序列

## 散列表 VS 二叉树
**二叉树优势**
1. 二叉树的中序遍历可以在时间复杂度为 O(N)的情况下输出`有序`的数据, 散列表需要, 先排序, 时间复杂度至少是O(N*logN)
2. 散列表为了解决 散列冲突, 会在装载因子越过阀值的时候, 做扩容操作, 性能不稳定, 一颗平衡的二叉树, 时间复杂度可以稳定在O(logN)
3. 因素一: 哈希函数的存在, 因素二:散列冲突的解决, 也会耗时, 比较常用的开发寻址法, 需要遍历对比key值, 链表法, 需要遍历链表对比key值, 由于这俩个因素查询的时间复杂度不一定比二叉树的O(logN)快, 
4. 由于 散列冲突, 还会浪费一些空间
5. 散列表的设计需要 考虑的因素太多了, 二叉树只需要考虑平衡性

## 平衡二叉树
对比散列表的时候, 提到了平衡二叉树.  因为二叉查找树在频繁的插入、删除等动态更新的情况下，极端情况会出现时间复杂度退化为O(N)的问题,  在二叉搜索树的基础上加上一个平衡因子 ,就是平衡二叉树, 平衡二叉树让数据的插入, 删除, 查找时间复杂度更稳定  

### AVL树
一棵**严格**平衡的二叉搜索树  
**平衡因子(node) ** = Height(RightSubtree(node)) - Height(LeftSubtree(node))  
**平衡因子 的范围 {-1,0,1} **  
![AVLTreeBalanceFactor.png](../images/AVLTreeBalanceFactor.png)  

**平衡(Rebalancing) **   
1. 左旋 左旋  
2. 右旋 右旋
3. 左旋 右旋
4. 右旋 左旋

![treeRotation.png](../images/treeRotation.png)  

### 红黑树
一棵**相对**平衡的二叉搜索树   
**平衡因子(node) ** = Height(RightSubtree(node)) - Height(LeftSubtree(node))  
**平衡因子 的范围  **  Height(RightSubtree(node)) <= Height(LeftSubtree(node)) * 2 - Height(RightSubtree(node))

**红黑树的特性**
1. 结点不是黑就是白
2. 根是黑色的。 有时会忽略此规则。 由于根始终可以从红色更改为黑色，但不一定反之亦然，因此该规则对分析的影响很小。
3. 所有的叶子结点都是`NIL` 且为黑色
4. 如果一个结点是红色, 那么它的子节点均为黑色 (不能有相邻的结点同时为红色)
5. 从给定节点到其任何后代NIL节点的每条路径都经过相同数量的黑色节点。
![redBlackTree.png](../images/redBlackTree.png)

### AVL 对比 红黑树
**AVL 优势** 由于是一棵**严格**平衡的二叉搜索树, 所以`查询`的速度很快

**AVL 劣势** 
1. 也是由于**严格** 造成维护的成本很高, 所以`插入` `删除` 的速度相较于`红黑树`会慢些
2. 也是由于**严格**需要记录 平衡因子 的空间成本较 `红黑树` 会高些

**红黑树 优势**  
1. 由于是一棵**相对**平衡的二叉搜索树, 所以`插入` `删除` 的速度相较于`AVL树`会快些
2. 需要记录 平衡因子 的空间成本较 基本可以忽略, 仅需要 1bit

**红黑树 劣势**  由于是一棵**相对**平衡的二叉搜索树, 所以`查找` 的速度相较于`AVL树`会慢些

## 动态的数据结构
`散列表`：插入删除查找都是O(1), 是最常用的，但其缺点是不能顺序遍历以及扩容缩容的性能损耗。适用于那些不需要顺序遍历，数据更新不那么频繁的。

`跳表`：插入删除查找都是O(logn), 并且能顺序遍历。缺点是空间复杂度O(n)。适用于不那么在意内存空间的，其顺序遍历和区间查找非常方便。

`红黑树`：插入删除查找都是O(logn), 中序遍历即是顺序遍历，稳定。缺点是难以实现，去查找不方便。其实跳表更佳，但红黑树已经用于很多地方了。

## 参考网址
[王争 -- 算法于数据之美](https://time.geekbang.org/column/article/68334)
[维基百科](https://en.wikipedia.org/wiki/Self-balancing_binary_search_tree)